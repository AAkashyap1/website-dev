I"ø<hr />

<p>The problem of visual interestingness detection, which is crucial for many practical applications such as search and rescue, is explored in this project. Although prior research is able to detect significant objects or scenes, it is not able to adapt in real-time and loose interest over time after repeatedly observing the same objects or exploring the same scenes. To enable such behaviours for robots, we argue that a learning system should have both life-time human-like experience learned from a large amount of unlabeled data and a short-term learning capability for limited negative labeled data. This is because robots normally only know uninteresting objects before a mission and have to change their interests during a mission. To this end, we introduce an unsupervised learning model with a memory mechanism, which is able to train in real-time without back-propagation, resulting in a much faster learning speed. Our experiments show that, although implemented on a single machine, our approach is still able to learn online and find meaningful objects for a practical search task in mine tunnels.</p>

<div class="video-wrapper"><iframe src="http://www.youtube.com/embed/PXIcm17fEko" frameborder="0" allowfullscreen=""></iframe></div>

<h3 id="approaches">Approaches</h3>
<p>We propose to establish an <strong>online learning</strong> scheme to search for interesting scenes for robot exploration. On the other hand, existing algorithms are heavily dependent on back-propagation algorithm for learning, which is very computationally expensive. To solve this problem, we introduce a novel translation-invariant 4-D visual memory to identify and recall visually interesting scenes. Human beings have a great capacity to direct visual attention and judge the interestingness of a scene.</p>

<p>For mobile robots, we find the following properties are necessary to establish a sense of visual interestingness:</p>

<ul>
  <li>
    <p><strong>Unsupervised</strong>: Visual interestingness is a psychological process. Its definition is subjective and can change according to one‚Äôs experience and environments, thus labels are difficult to obtain. However, prior research mainly focuses on supervised methods, and their performance suffers in a prior unseen environment. We hypothesize that a sense of interestingness can be established for autonomous robots in an unsupervised manner.</p>
  </li>
  <li>
    <p><strong>Task-dependent</strong>: In many tasks, we might only know uninteresting objects before the task is started. For example, in a mine rescue search task, the deployment will be more efficient and easier, if the robots can be taught what is not interesting in the specific scene within several minutes. In this sense, we argue that a visual interestingness detection system should be able to learn negative labeled samples quickly, thus an incremental learning method is necessary. Note that we expect the model is capable of learning negative samples, but it is not necessary in all tasks.</p>
  </li>
</ul>

<p>Therefore, to construct a practical interestingness detection system and achieve the above properties, we introduce an unsupervised online learning model with a novel memory mechanism and expect the following outcomes:</p>

<ul>
  <li>
    <p><strong>Long-term learning</strong>: In this stage, we expect a model to be trained off-line on a large amount of data in an unsupervised manner as human beings acquire common knowledge from experience. We also expect the training time on a single machine to be no more than the order of days.</p>
  </li>
  <li>
    <p><strong>Short-term learning</strong>: For task-dependent knowledge, the model then should be able to learn from hundreds of uninteresting images in minutes. This can be done before a mission starts and is beneficial to quick robot deployment.</p>
  </li>
  <li>
    <p><strong>Online learning</strong>: During mission execution the system should express the top interests in real-time and the detected interests should be lost online when they appear frequently, regardless if they exist in the uninteresting images or not. Another important aspect for online learning is no data leakage, i.e., each frame is proceeding without using information from its subsequent frames.</p>
  </li>
</ul>
<figure>
 <img src="/img/posts/2020-05-01-interestingness/image3crop.png" alt="interesting images" />
 <figcaption>
    Detected interesting scenes 
 </figcaption>
</figure>

<h3 id="key-results">Key Results</h3>
<p>In the <a href="https://www.darpa.mil/program/darpa-subterranean-challenge">DARPA Subterranean (SubT) Challenge</a>, each team deploys multiple robots into several mine tunnels (GPS and wireless communication denied) to search for objects. The tunnels have a cumulative linear distance in the range of 4-8 km. The <a href="http://theairlab.org/dataset/interestingness">SubT front camera (SubTF) dataset</a> contains seven long videos (1h) recorded by two fully autonomous unmanned ground vehicles (UGV) during their complete exploration in two tunnels during the tunnel circuit. Some of the video shots are presented in Figure 1. It can be seen that the SubTF dataset is very challenging, as the human annotation varies a lot, i.e. only 3.6% of the frames are labeled as interesting by at least 2 subjects, although 15% of the frames are labeled by at least 1 subject (Interest-1).</p>

<figure>
 <img src="/img/posts/2020-05-01-interestingness/image2.png" alt="interestingness score" />
 <figcaption>
    Fig. 1. This figure shows several examples of both uninteresting and interesting scenes in <a href="http://theairlab.org/dataset/interestingness">SubTF dataset</a> taken by the Team Explorer who won the first place in DARPA SubT Challenge tunnel circuit. The height of green strip located at the right of each image indicates the interestingness level predicted by our unsupervised online learning algorithm when it sees the scene for the first time.
 </figcaption>
</figure>

<p>Compared to human indicated interestingness the algorithm achieves an average 20% higher accuracy than the approach without online learning. The results indicate that our three-stage architecture of long-term, short-term, and online learning shows promise in representing interestingness for robots.</p>

<figure>
 <img src="/img/posts/2020-05-01-interestingness/image1.png" alt="map" style="width:70%" />
 <figcaption>
    The map created by Lidar during fully autonomous exploration
 </figcaption>
</figure>

<h3 id="project-members">Project Members</h3>
<ul>
  <li><a href="https://chenwang.site">Chen Wang</a></li>
  <li><a href="http://www.wangwenshan.com/">Wenshan Wang</a></li>
  <li>Yuheng Qiu</li>
  <li>Yafei Hu</li>
  <li>Sebastian Scherer</li>
</ul>

<h3 id="publication">Publication</h3>

<ul>
  <li>Chen Wang, Wenshan Wang, Yuheng Qiu, Yafei Hu, Sebastian Scherer, ‚ÄúVisual Memorability for Robotic Interestingness Prediction via Unsupervised Online Learning‚Äù. European Conference on Computer Vision (ECCV), 2020 [<a href="https://arxiv.org/abs/2005.08829">PDF</a>]</li>
</ul>

<h3 id="source-codes">Source Codes</h3>

<ul>
  <li>
    <p>Plain Python Package: <a href="https://github.com/wang-chen/interestingness">interestingness</a></p>
  </li>
  <li>
    <p>ROS Package: <a href="https://github.com/wang-chen/interestingness_ros">interestingness_ros</a></p>
  </li>
</ul>

<h3 id="citation">Citation</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  @inproceedings{wang2020visual,
     title={Visual Memorability for Robotic Interestingness via Unsupervised Online Learning},
     author={Wang, Chen and Wang, Wenshan and Qiu, Yuheng and Hu, Yafei and Scherer, Sebastian},
     booktitle={European Conference on Computer Vision (ECCV)},
     year={2020},
  }
</code></pre></div></div>
:ET